#!/usr/bin/env python3
"""
Ù…Ø¹Ø§Ù„Ø¬Ø© Ø°ÙƒÙŠØ© Ù„Ù„Ø¥Ø·Ø§Ø±Ø§Øª - ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø·Ø§Ø± Ø¨Ø¯Ù‚Ø© ÙˆØªØºÙ…ÙŠÙ‚Ù‡ Ù‚Ø¨Ù„ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
Smart Frame Processing - Precisely detect frame and darken before background removal
"""

from PIL import Image, ImageFilter, ImageEnhance
import numpy as np
import cv2
from scipy import ndimage
import os

def smart_detect_frame(img_array):
    """
    ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø·Ø§Ø± Ø¨Ø°ÙƒØ§Ø¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… edge detection Ùˆ morphology
    Smart frame detection using edge detection and morphology
    """
    h, w = img_array.shape[:2]
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ grayscale
    if len(img_array.shape) == 3:
        gray = cv2.cvtColor(img_array[:, :, :3], cv2.COLOR_RGB2GRAY)
    else:
        gray = img_array
    
    # Gaussian blur Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Canny edge detection
    edges = cv2.Canny(blurred, 30, 100)
    
    # Morphological operations Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­ÙˆØ§Ù
    kernel = np.ones((3, 3), np.uint8)
    edges_dilated = cv2.dilate(edges, kernel, iterations=2)
    
    # Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„contours
    contours, _ = cv2.findContours(edges_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Ø¥Ù†Ø´Ø§Ø¡ mask Ù„Ù„Ø¥Ø·Ø§Ø±
    frame_mask = np.zeros((h, w), dtype=np.uint8)
    
    # Ù†Ø±Ø³Ù… Ø§Ù„contours Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø§Ø³Ùƒ
    if contours:
        # Ù†Ø£Ø®Ø° Ø£ÙƒØ¨Ø± contour (Ø¹Ø§Ø¯Ø© ÙŠÙƒÙˆÙ† Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ)
        contours_sorted = sorted(contours, key=cv2.contourArea, reverse=True)
        
        # Ù†Ø±Ø³Ù… Ø£ÙƒØ¨Ø± Ø¹Ø¯Ø© contours
        for i, contour in enumerate(contours_sorted[:5]):
            area = cv2.contourArea(contour)
            if area > 100:  # Ù†ØªØ¬Ø§Ù‡Ù„ Ø§Ù„contours Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                cv2.drawContours(frame_mask, [contour], -1, 255, thickness=20)
    
    # Morphological closing Ù„Ù…Ù„Ø¡ Ø§Ù„ÙØ±Ø§ØºØ§Øª
    kernel_large = np.ones((15, 15), np.uint8)
    frame_mask = cv2.morphologyEx(frame_mask, cv2.MORPH_CLOSE, kernel_large)
    
    # Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø­ÙˆØ§Ù (Ø§Ù„Ø¥Ø·Ø§Ø± Ø¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ø­ÙˆØ§Ù)
    border_width = 60
    frame_mask[:border_width, :] = 255
    frame_mask[-border_width:, :] = 255
    frame_mask[:, :border_width] = 255
    frame_mask[:, -border_width:] = 255
    
    return frame_mask > 0

def detect_background_smartly(img_array, frame_mask):
    """
    ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ø°ÙƒØ§Ø¡ - ÙÙ‚Ø· Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ÙØ§ØªØ­Ø© Ø§Ù„ØªÙŠ Ù„ÙŠØ³Øª Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¥Ø·Ø§Ø±
    Smart background detection - only bright areas that are not part of the frame
    """
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø·ÙˆØ¹
    brightness = np.mean(img_array[:, :, :3], axis=2)
    
    # Ø§Ù„Ø®Ù„ÙÙŠØ© = Ù…Ù†Ø§Ø·Ù‚ ÙØ§ØªØ­Ø© Ø¬Ø¯Ø§Ù‹ (> 235) ÙˆÙ„ÙŠØ³Øª Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¥Ø·Ø§Ø±
    very_bright = brightness > 235
    background_mask = very_bright & (~frame_mask)
    
    # ØªÙˆØ³ÙŠØ¹ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… dilation
    kernel = np.ones((5, 5), np.uint8)
    background_mask = cv2.dilate(background_mask.astype(np.uint8), kernel, iterations=1)
    
    return background_mask > 0

def darken_frame_only(img_array, frame_mask, darken_factor=0.55):
    """
    ØªØºÙ…ÙŠÙ‚ Ø§Ù„Ø¥Ø·Ø§Ø± ÙÙ‚Ø· (Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø¨Ø§Ù„Ù…Ø§Ø³Ùƒ)
    Darken only the frame (areas specified by mask)
    """
    # Ù†ØºÙ…Ù‚ ÙÙ‚Ø· Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ÙØ§ØªØ­Ø© ÙÙŠ Ø§Ù„Ø¥Ø·Ø§Ø±
    brightness = np.mean(img_array[:, :, :3], axis=2)
    bright_frame = frame_mask & (brightness > 180)
    
    # ØªØºÙ…ÙŠÙ‚
    img_array[bright_frame, :3] = (img_array[bright_frame, :3] * darken_factor).astype(np.uint8)
    
    return img_array

def process_frame_smart(frame_img, darken_factor=0.55):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø·Ø§Ø± ÙˆØ§Ø­Ø¯ Ø¨Ø°ÙƒØ§Ø¡
    Process single frame intelligently
    """
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ numpy array
    img_array = np.array(frame_img, dtype=np.uint8)
    h, w = img_array.shape[:2]
    
    # Step 1: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø·Ø§Ø± Ø¨Ø°ÙƒØ§Ø¡
    print(f"      1ï¸âƒ£ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø·Ø§Ø± Ø¨Ù€ Edge Detection...")
    frame_mask = smart_detect_frame(img_array)
    frame_pixels = frame_mask.sum()
    print(f"         âœ“ ØªÙ… ØªØ­Ø¯ÙŠØ¯ {frame_pixels:,} Ø¨ÙƒØ³Ù„ ÙƒØ¥Ø·Ø§Ø± ({frame_pixels/(h*w)*100:.1f}%)")
    
    # Step 2: ØªØºÙ…ÙŠÙ‚ Ø§Ù„Ø¥Ø·Ø§Ø± ÙÙ‚Ø·
    print(f"      2ï¸âƒ£ ØªØºÙ…ÙŠÙ‚ Ø§Ù„Ø¥Ø·Ø§Ø± ÙÙ‚Ø· (factor: {darken_factor})...")
    img_array = darken_frame_only(img_array, frame_mask, darken_factor)
    
    # Step 3: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø®Ù„ÙÙŠØ©
    print(f"      3ï¸âƒ£ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ø°ÙƒØ§Ø¡...")
    background_mask = detect_background_smartly(img_array, frame_mask)
    bg_pixels = background_mask.sum()
    print(f"         âœ“ ØªÙ… ØªØ­Ø¯ÙŠØ¯ {bg_pixels:,} Ø¨ÙƒØ³Ù„ ÙƒØ®Ù„ÙÙŠØ© ({bg_pixels/(h*w)*100:.1f}%)")
    
    # Step 4: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
    print(f"      4ï¸âƒ£ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©...")
    if img_array.shape[2] == 4:
        img_array[background_mask, 3] = 0  # Ø¬Ø¹Ù„ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø´ÙØ§ÙØ©
    
    processed_frame = Image.fromarray(img_array)
    return processed_frame

def process_gif_smart(input_path, output_path, darken_factor=0.55):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© GIF Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø°ÙƒØ§Ø¡
    Process entire GIF intelligently
    """
    print(f"\n{'='*70}")
    print(f"ğŸ§  Ù…Ø¹Ø§Ù„Ø¬Ø© Ø°ÙƒÙŠØ©: {os.path.basename(input_path)}")
    print(f"{'='*70}\n")
    
    gif = Image.open(input_path)
    frames_processed = []
    durations = []
    frame_count = 0
    
    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø£ÙˆÙ„ Ø¨Ø´ÙƒÙ„ Ù…ÙØµÙ„
        frame = gif.copy()
        duration = frame.info.get('duration', 50)
        durations.append(duration)
        
        if frame.mode != 'RGBA':
            frame = frame.convert('RGBA')
        
        print(f"ğŸ”§ Ø§Ù„Ø¥Ø·Ø§Ø± 1 (Ù…Ø¹Ø§Ù„Ø¬Ø© ØªÙØµÙŠÙ„ÙŠØ©):")
        processed = process_frame_smart(frame, darken_factor)
        frames_processed.append(processed)
        frame_count = 1
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø¨Ø³Ø±Ø¹Ø©
        while True:
            gif.seek(gif.tell() + 1)
            frame = gif.copy()
            duration = frame.info.get('duration', 50)
            durations.append(duration)
            
            if frame.mode != 'RGBA':
                frame = frame.convert('RGBA')
            
            frame_count += 1
            if frame_count % 10 == 0:
                print(f"   ... Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø± {frame_count}")
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø°ÙƒÙŠØ©
            img_array = np.array(frame, dtype=np.uint8)
            frame_mask = smart_detect_frame(img_array)
            img_array = darken_frame_only(img_array, frame_mask, darken_factor)
            background_mask = detect_background_smartly(img_array, frame_mask)
            if img_array.shape[2] == 4:
                img_array[background_mask, 3] = 0
            processed = Image.fromarray(img_array)
            frames_processed.append(processed)
            
    except EOFError:
        pass
    
    print(f"\nğŸ’¾ Ø­ÙØ¸ {frame_count} Ø¥Ø·Ø§Ø±...")
    
    frames_processed[0].save(
        output_path,
        save_all=True,
        append_images=frames_processed[1:],
        duration=durations,
        loop=0,
        disposal=2,
        optimize=False,
        transparency=0
    )
    
    size_mb = os.path.getsize(output_path) / (1024 * 1024)
    print(f"\nâœ… ØªÙ… Ø§Ù„Ø­ÙØ¸!")
    print(f"ğŸ“ {output_path}")
    print(f"ğŸ“Š Ø§Ù„Ø­Ø¬Ù…: {size_mb:.2f} MB")
    print(f"ğŸ¬ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª: {frame_count}\n")
    
    return True

def test_on_single_frame():
    """
    Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± ÙˆØ§Ø­Ø¯
    Test on single frame
    """
    print("\n" + "ğŸ§ª " + "="*68)
    print("ğŸ§ª  Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø¹Ù„Ù‰ frame10")
    print("ğŸ§ª " + "="*68 + "\n")
    
    input_file = '/workspace/client/public/frames/frame10_animated.gif'
    output_file = '/workspace/client/public/frames/frame10_SMART_TEST.gif'
    
    # Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
    import shutil
    backup_file = input_file.replace('.gif', '_BACKUP.gif')
    if not os.path.exists(backup_file):
        print(f"ğŸ’¾ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©...")
        shutil.copy(input_file, backup_file)
    
    success = process_gif_smart(input_file, output_file, darken_factor=0.55)
    
    if success:
        print("="*70)
        print("âœ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¬Ø­! ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©:")
        print(f"   ğŸ“ Ø§Ù„Ø£ØµÙ„ÙŠ: {input_file}")
        print(f"   ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø©: {output_file}")
        print(f"   ğŸ“ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_file}")
        print("="*70 + "\n")
    
    return success

if __name__ == '__main__':
    test_on_single_frame()
